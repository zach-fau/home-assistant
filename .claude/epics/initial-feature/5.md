---
name: Core Pipecat Pipeline with STT and TTS
status: completed
created: 2025-10-28T20:51:52Z
updated: 2025-10-28T22:20:00Z
completed: 2025-10-28T22:20:00Z
github: https://github.com/zach-fau/home-assistant/issues/5
depends_on: [4]
parallel: false
conflicts_with: []
resolution: Critical bug fix - added audio_in_enabled and audio_out_enabled parameters
final_commit: d185e66
---

# Task: Core Pipecat Pipeline with STT and TTS

## Description
Implement the foundational conversation pipeline using Pipecat framework with Deepgram speech-to-text and Cartesia Sonic text-to-speech. Create a working "echo bot" that captures audio input, transcribes it, and speaks it back to validate the core audio processing pipeline before adding LLM intelligence.

## Acceptance Criteria
- [ ] Pipecat pipeline configured with audio I/O transport
- [ ] Deepgram WebSocket integration for streaming STT working
- [ ] Cartesia Sonic TTS integration generating natural speech
- [ ] Audio input/output handling with microphone and speakers
- [ ] Basic conversation loop: listen → transcribe → speak back
- [ ] Pipeline handles interruptions and barge-in gracefully
- [ ] Latency measurements logged (STT and TTS separately)
- [ ] Pipeline can be started, stopped, and restarted reliably

## Technical Details
**Pipecat Pipeline Architecture:**
```python
# Core pipeline flow
AudioInput (Microphone)
  → DeepgramSTT (streaming transcription)
  → Pipecat Context Manager
  → CartesiaTTS (speech synthesis)
  → AudioOutput (Speaker)
```

**Implementation Approach:**
1. Configure Pipecat transport for audio I/O (use default audio backend)
2. Initialize Deepgram client with WebSocket for streaming
3. Set up Deepgram STT processor in pipeline
4. Initialize Cartesia Sonic client for TTS
5. Set up TTS processor in pipeline
6. Implement simple echo logic: transcription → immediate TTS playback
7. Add conversation state management via Pipecat context

**Key Considerations:**
- Use Deepgram Nova-2 model for best accuracy/latency
- Configure Deepgram for interim results to reduce perceived latency
- Cartesia Sonic voice selection (choose natural-sounding default)
- Audio sample rate and format compatibility between components
- Proper cleanup of WebSocket connections on shutdown

**Testing Approach:**
- Verify audio input is captured correctly
- Test STT with various phrases and accents
- Validate TTS output sounds natural
- Measure end-to-end latency (target < 2 seconds)
- Test interruption handling (user speaks while bot is speaking)

## Dependencies
- [ ] Task 001 (Project Foundation) completed
- [ ] Deepgram API key configured
- [ ] Cartesia API key configured
- [ ] Audio hardware (microphone and speakers) available

## Effort Estimate
- Size: M
- Hours: 8-12 hours
- Parallel: false (foundation for all LLM and tool work)

## Definition of Done
- [ ] Pipeline successfully processes "echo bot" conversations
- [ ] STT accurately transcribes clear speech (> 95% accuracy on test phrases)
- [ ] TTS produces natural-sounding speech output
- [ ] Audio I/O works reliably without glitches
- [ ] Interruptions handled gracefully without crashes
- [ ] Latency measurements show STT < 500ms, TTS < 300ms to first audio
- [ ] Pipeline can run continuously for 5+ minutes without issues
- [ ] Code includes error handling for API failures
- [ ] Integration tests validate full pipeline operation
