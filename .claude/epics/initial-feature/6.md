---
name: LLM Integration with Function Calling Framework
status: open
created: 2025-10-28T20:51:52Z
updated: 2025-10-28T21:06:48Z
github: https://github.com/zach-fau/home-assistant/issues/6
depends_on: [5]
parallel: false
conflicts_with: []
---

# Task: LLM Integration with Function Calling Framework

## Description
Integrate GPT-4o-mini into the Pipecat pipeline with streaming responses and implement the function calling framework that enables the LLM to dynamically invoke tools. Replace the echo bot logic with intelligent conversation handling, including tool registration, execution, and response generation. Validate with a simple timer tool as proof of concept.

## Acceptance Criteria
- [ ] GPT-4o-mini integrated into Pipecat pipeline with streaming
- [ ] Function calling schema system implemented
- [ ] Tool registration interface defined and working
- [ ] Tool execution layer handles function calls from LLM
- [ ] Conversation context maintained across multiple turns
- [ ] Simple timer tool implemented as validation
- [ ] LLM correctly determines when to call timer tool vs. conversational response
- [ ] Tool results integrated back into conversation naturally

## Technical Details
**Pipeline Flow Update:**
```python
AudioInput → DeepgramSTT
  → GPT-4o-mini (with function calling)
  → Tool Executor (if function called)
  → Response Generator
  → CartesiaTTS → AudioOutput
```

**Function Calling Framework:**
```python
class Tool(ABC):
    """Base class for all tools"""
    @property
    @abstractmethod
    def name(self) -> str:
        pass

    @property
    @abstractmethod
    def description(self) -> str:
        pass

    @property
    @abstractmethod
    def parameters(self) -> dict:
        """JSON Schema for parameters"""
        pass

    @abstractmethod
    async def execute(self, **kwargs) -> dict:
        """Execute the tool and return results"""
        pass

class ToolRegistry:
    """Manages tool registration and execution"""
    def register(self, tool: Tool):
        pass

    def get_openai_functions(self) -> list[dict]:
        """Convert tools to OpenAI function format"""
        pass

    async def execute_function(self, name: str, arguments: dict) -> dict:
        pass
```

**Simple Timer Tool (Validation):**
```python
class TimerTool(Tool):
    name = "set_timer"
    description = "Set a timer for a specified duration"
    parameters = {
        "type": "object",
        "properties": {
            "duration_seconds": {"type": "integer", "description": "Duration in seconds"},
            "label": {"type": "string", "description": "Optional label for the timer"}
        },
        "required": ["duration_seconds"]
    }

    async def execute(self, duration_seconds: int, label: str = None) -> dict:
        # Start async timer, return confirmation
        pass
```

**OpenAI Integration:**
- Use OpenAI client with streaming enabled
- Pass tool definitions in chat completion request
- Handle function calling responses
- Execute tools and return results to LLM for final response
- Maintain conversation history for context

**Conversation Context Management:**
- Store message history (user, assistant, function results)
- Implement context window management (truncate old messages if needed)
- Preserve important context across turns

## Dependencies
- [ ] Task 002 (Core Pipeline) completed
- [ ] OpenAI API key configured
- [ ] Pipecat pipeline running successfully

## Effort Estimate
- Size: L
- Hours: 12-16 hours
- Parallel: false (required for all tool implementations)

## Definition of Done
- [ ] GPT-4o-mini responds intelligently to conversational queries
- [ ] Function calling correctly triggers when user requests timer
- [ ] Timer tool successfully executes with proper parameters
- [ ] Tool results are incorporated into natural language responses
- [ ] Conversation context maintained across at least 5 turns
- [ ] LLM streaming reduces perceived latency (< 1.5s to first token)
- [ ] Error handling for tool execution failures
- [ ] Code includes comprehensive logging of function calls
- [ ] Unit tests for tool registration and execution
- [ ] Integration test: "Set a timer for 30 seconds" works end-to-end
