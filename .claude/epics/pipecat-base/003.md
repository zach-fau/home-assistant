---
name: Basic Pipeline Validation
status: completed
created: 2025-10-29T00:19:22Z
updated: 2025-10-29T00:45:00Z
github: null
depends_on: [1, 2]
parallel: false
conflicts_with: []
---

# Task: Basic Pipeline Validation

## Description

Install dependencies and run the pipecat-quickstart bot to validate that the complete voice interaction pipeline works end-to-end. This task confirms that all services integrate correctly and establishes a working baseline before customization.

**Goal:** Achieve first successful voice conversation with the assistant.

## Acceptance Criteria

- [ ] All dependencies installed via `uv sync`
- [ ] Bot starts successfully with `uv run bot.py`
- [ ] Web client accessible at http://localhost:7860/client
- [ ] Microphone permission granted in browser
- [ ] Can speak to assistant and hear audio response
- [ ] End-to-end latency feels acceptable (<1-2 seconds)
- [ ] No critical errors in console output
- [ ] Multi-turn conversation works (3+ exchanges)
- [ ] Basic pipeline flow documented

## Technical Details

### Installation Steps

1. **Install Dependencies**
   ```bash
   cd pipecat-quickstart
   uv sync
   ```

   This installs:
   - pipecat-ai core framework
   - Service integrations (Deepgram, OpenAI, Cartesia)
   - WebRTC transport (Daily.co)
   - VAD (Voice Activity Detection)
   - All other dependencies from pyproject.toml

2. **Start the Bot**
   ```bash
   uv run bot.py
   ```

   Expected output:
   ```
   Starting Pipecat bot...
   Connecting to services...
   Server running at http://localhost:7860
   ```

3. **Access Web Client**
   - Open browser: http://localhost:7860/client
   - Grant microphone permissions
   - Click "Connect" or "Start"

4. **Test Voice Interaction**
   - Speak: "Hello, can you hear me?"
   - Wait for assistant response
   - Observe latency and audio quality
   - Try 2-3 more exchanges

### Pipeline Flow Validation

**Verify Each Stage:**

1. **Audio Capture** ✓
   - Microphone working
   - Browser permissions granted
   - Audio streaming to server

2. **VAD (Voice Activity Detection)** ✓
   - Detects speech start
   - Detects speech end
   - ~200ms stop threshold

3. **STT (Speech-to-Text)** ✓
   - Deepgram transcribing speech
   - Real-time streaming
   - Acceptable word error rate

4. **LLM (Language Model)** ✓
   - OpenAI processing input
   - Generating responses
   - Streaming tokens back

5. **TTS (Text-to-Speech)** ✓
   - Cartesia synthesizing voice
   - Natural-sounding output
   - Acceptable latency

6. **Audio Output** ✓
   - Browser playing response
   - Clear audio quality
   - Proper synchronization

### Key Considerations

- **Initial Startup:** First run takes ~20 seconds to download models
- **Latency:** Expect 500-800ms end-to-end in ideal conditions
- **Browser:** Use Chrome or Firefox for best WebRTC support
- **Network:** Stable internet required for API calls

### Files Affected

- `bot.py` (no changes yet - just running default)
- Local model cache (created on first run)

## Dependencies

### External Dependencies
- [ ] Stable internet connection (>1Mbps)
- [ ] Modern browser (Chrome/Firefox recommended)
- [ ] Microphone and speaker access

### Task Dependencies
- [ ] Task 001 (Environment Setup) complete
- [ ] Task 002 (Service Configuration) complete

## Effort Estimate

- **Size:** S
- **Hours:** 1-2 hours (including troubleshooting)
- **Parallel:** false (prerequisite for customization tasks)

## Implementation Notes

### Expected Console Output

```
INFO: Started server process [12345]
INFO: Waiting for application startup.
INFO: Application startup complete.
INFO: Uvicorn running on http://localhost:7860
INFO: Client connected
INFO: Pipeline started
INFO: STT: Hello, can you hear me?
INFO: LLM: Yes, I can hear you! How can I help you today?
INFO: TTS: Synthesizing response...
```

### Testing Checklist

Run through this test script:

1. **Basic Greeting**
   - Say: "Hello"
   - Expect: Friendly greeting back

2. **Simple Question**
   - Say: "What's the weather like?"
   - Expect: Reasonable response (won't have real weather data)

3. **Multi-turn Context**
   - Say: "Tell me about Python"
   - Say: "What makes it popular?"
   - Expect: Second response refers to Python from first question

4. **Interruption Test**
   - Start speaking
   - Interrupt yourself
   - Expect: VAD handles properly

### Troubleshooting Common Issues

**Issue:** "Connection refused" error
**Solution:** Ensure bot is running, check port 7860 not in use
```bash
lsof -ti:7860 | xargs kill -9  # Kill any process on port 7860
uv run bot.py
```

**Issue:** Microphone not working
**Solution:** Check browser permissions, verify hardware
- Chrome: Settings > Privacy > Site Settings > Microphone
- Firefox: Preferences > Privacy > Permissions > Microphone

**Issue:** High latency (>2 seconds)
**Solution:** Check internet connection, verify service status
- Test: Run on different network
- Check: Deepgram, OpenAI status pages

**Issue:** "API key invalid" errors
**Solution:** Verify .env configuration
```bash
cat .env  # Check keys are present
uv run python -c "import os; from dotenv import load_dotenv; load_dotenv(); print(os.getenv('DEEPGRAM_API_KEY'))"
```

**Issue:** Import errors or missing modules
**Solution:** Reinstall dependencies
```bash
rm -rf .venv
uv sync
```

## Validation Tests

### Test 1: Single Exchange
```
User: "Hello"
Assistant: [Should respond within 1-2 seconds]
Result: PASS/FAIL
```

### Test 2: Multi-turn Context
```
User: "My name is Alex"
User: "What's my name?"
Assistant: [Should remember "Alex"]
Result: PASS/FAIL
```

### Test 3: Latency Measurement
```
Speak → Wait → Response received
Measured latency: _____ ms
Target: <1000ms acceptable, <800ms good
Result: PASS/FAIL
```

### Test 4: Error Recovery
```
Action: Disconnect/reconnect
Result: Bot handles gracefully? PASS/FAIL
```

## Documentation

After validation, document:

1. **Working Configuration**
   - Python version used
   - Browser and OS
   - Observed latency
   - Any quirks or issues

2. **Pipeline Behavior**
   - VAD responsiveness
   - Audio quality observations
   - Context memory behavior

3. **Known Issues**
   - List any problems encountered
   - Workarounds applied
   - Items to address in tuning

## Definition of Done

- [ ] Dependencies installed successfully
- [ ] Bot runs without critical errors
- [ ] Web client accessible
- [ ] Voice interaction works end-to-end
- [ ] Multi-turn conversation confirmed
- [ ] Latency measured and documented
- [ ] Pipeline stages validated
- [ ] Known issues documented
- [ ] Ready for customization phase

## References

- Pipecat Quickstart README: https://github.com/pipecat-ai/pipecat-quickstart
- Pipecat Reference: `.claude/docs/pipecat-reference.md`
- Browser WebRTC Support: https://caniuse.com/webrtc
