# Home Voice Assistant Configuration
# Copy this file to .env and fill in your actual values

# =============================================================================
# API Keys
# =============================================================================

# Deepgram API Key (for speech-to-text)
# Get yours at: https://console.deepgram.com/
DEEPGRAM_API_KEY=your_deepgram_api_key_here

# OpenAI API Key (for language model)
# Get yours at: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Cartesia API Key (for text-to-speech)
# Get yours at: https://cartesia.ai/
CARTESIA_API_KEY=your_cartesia_api_key_here

# =============================================================================
# Home Assistant Configuration
# =============================================================================

# Home Assistant instance URL (no trailing slash)
HOME_ASSISTANT_URL=http://localhost:8123

# Home Assistant long-lived access token
# Create one at: http://your-ha-url:8123/profile/security
HOME_ASSISTANT_TOKEN=your_home_assistant_token_here

# Whether to verify SSL certificates (set to false for self-signed certs)
HOME_ASSISTANT_VERIFY_SSL=true

# =============================================================================
# Logging Configuration
# =============================================================================

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log format (standard Python logging format)
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# Output logs in JSON format (useful for log aggregation)
LOG_JSON_FORMAT=false

# =============================================================================
# Application Settings
# =============================================================================

# Enable debug mode
DEBUG=false

# =============================================================================
# Audio Configuration
# =============================================================================

# Audio sample rate in Hz (8000, 16000, 24000, or 48000)
AUDIO_SAMPLE_RATE=16000

# Number of audio channels (1=mono, 2=stereo)
AUDIO_CHANNELS=1

# Audio chunk size for processing
AUDIO_CHUNK_SIZE=1024

# Input device index (leave empty for default microphone)
# Use 'python -m src.cli echo-bot --list-devices' to see available devices
# AUDIO_INPUT_DEVICE=

# Output device index (leave empty for default speaker)
# AUDIO_OUTPUT_DEVICE=

# =============================================================================
# Pipeline Configuration
# =============================================================================

# Speech-to-Text Settings
# Deepgram model: nova-2 (recommended), nova, enhanced, base
STT_MODEL=nova-2

# Speech recognition language (en-US, en-GB, es, fr, de, etc.)
STT_LANGUAGE=en-US

# Enable interim results for lower latency (true/false)
STT_INTERIM_RESULTS=true

# Text-to-Speech Settings
# Cartesia voice ID (see https://docs.cartesia.ai for options)
# Default: Barbershop Man - 79a125e8-cd45-4c13-8a67-188112f4dd22
TTS_VOICE=79a125e8-cd45-4c13-8a67-188112f4dd22

# Cartesia model: sonic-english, sonic-multilingual
TTS_MODEL=sonic-english

# Pipeline Behavior
# Maximum silence duration before ending utterance (seconds)
PIPELINE_MAX_SILENCE=1.5

# Allow user to interrupt bot speech (true/false)
PIPELINE_ENABLE_INTERRUPTIONS=true
